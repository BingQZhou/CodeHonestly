{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 158 HW 2\n",
    "#### Hongtao Jiang A13760857\n",
    "#### 10/22/19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before answering the questions, I imported all the models that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import arff\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I imported the data。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"5year.arff\", 'r')\n",
    "while not '@data' in f.readline():\n",
    "    pass\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if '?' in l: # Missing entry\n",
    "        continue\n",
    "    l = l.split(',')\n",
    "    values = [1] + [float(x) for x in l]\n",
    "    values[-1] = values[-1] > 0 # Convert to bool\n",
    "    dataset.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [values[:-1] for values in dataset]\n",
    "y = [values[-1] for values in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Question: Train a logistic regressor (e.g. sklearn.linear model.LogisticRegression) with regularization coefficient C = 1.0. Report the accuracy and Balanced Error Rate (BER) of your classifier (1 mark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer for Question 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = linear_model.LogisticRegression(C=1.0)\n",
    "model_1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9666776641372484\n",
      "Balanced Error Rate: 0.48090427704028005\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score:', metrics.accuracy_score(y, predictions))\n",
    "print('Balanced Error Rate:', 1 - metrics.balanced_accuracy_score(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Question: Retrain the above model using the class weight=’balanced’ option. Report the accuracy and BER of your new classifier (1 mark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer for Question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = linear_model.LogisticRegression(C=1.0, class_weight='balanced')\n",
    "model_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = model_2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7806004618937644\n",
      "Balanced Error Rate: 0.2034137997978297\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score:', \n",
    "      metrics.accuracy_score(y, predictions_2))\n",
    "print('Balanced Error Rate:', \n",
    "      1 - metrics.balanced_accuracy_score(y, predictions_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Question: Shuffle the data, and split it into training, validation, and test splits, with a 50/25/25% ratio. Using the class weight=’balanced’ option, and training on the training set, report the training/validation/test accuracy and BER (1 mark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer for Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [values[:-1] for values in dataset]\n",
    "y = [values[-1] for values in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X[:len(X)//2]\n",
    "X_test=X[len(X)*3//4:]\n",
    "X_vali=X[len(X)//2:len(X)*3//4] \n",
    "y_train=y[:len(X)//2]\n",
    "y_test=y[len(X)*3//4:]\n",
    "y_vali=y[len(X)//2:len(X)*3//4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3031, 1515, 758, 758)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(X_train), len(X_test), len(X_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = linear_model.LogisticRegression(C=1.0, class_weight='balanced')\n",
    "model_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_3 = model_3.predict(X_train)\n",
    "vali_predictions_3 = model_3.predict(X_vali)\n",
    "test_predictions_3 = model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Accuracy Score: 0.7973597359735973\n",
      "TRAIN Balanced Error Rate: 0.16273037542662117\n"
     ]
    }
   ],
   "source": [
    "print('TRAIN Accuracy Score:', \n",
    "      metrics.accuracy_score(y_train, train_predictions_3))\n",
    "print('TRAIN Balanced Error Rate:', \n",
    "      1 - metrics.balanced_accuracy_score(y_train, train_predictions_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION Accuracy Score: 0.7823218997361477\n",
      "VALIDATION Balanced Error Rate: 0.31908023483365944\n"
     ]
    }
   ],
   "source": [
    "print('VALIDATION Accuracy Score:', \n",
    "      metrics.accuracy_score(y_vali, vali_predictions_3))\n",
    "print('VALIDATION Balanced Error Rate:', \n",
    "      1 - metrics.balanced_accuracy_score(y_vali, vali_predictions_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Accuracy Score: 0.7770448548812665\n",
      "TEST Balanced Error Rate: 0.31664396003633066\n"
     ]
    }
   ],
   "source": [
    "print('TEST Accuracy Score:', \n",
    "      metrics.accuracy_score(y_test, test_predictions_3))\n",
    "print('TEST Balanced Error Rate:', \n",
    "      1 - metrics.balanced_accuracy_score(y_test, test_predictions_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Question: Implement a complete regularization pipeline. Consider values of C in the range {10−4, 10−3, . . . , 103, 104}. Report (or plot) the train, validation, and test BER for each value of C. Based on these values, which classifier would you select (in terms of generalization performance) and why (1 mark)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer for Question 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Accuracy Score for C = 0.0001: 0.7755775577557755\n",
      "TRAIN Balanced Error Rate for C = 0.0001: 0.2512627986348124\n",
      "TEST Accuracy Score for C = 0.0001: 0.7519788918205804\n",
      "TEST Balanced Error Rate for C = 0.0001: 0.30943460490463215\n",
      "VALIDATION Accuracy Score for C = 0.0001: 0.7612137203166227\n",
      "VALIDATION Balanced Error Rate for C = 0.0001: 0.3987279843444227\n",
      "\n",
      "TRAIN Accuracy Score for C = 0.001: 0.8092409240924092\n",
      "TRAIN Balanced Error Rate for C = 0.001: 0.1759044368600683\n",
      "TEST Accuracy Score for C = 0.001: 0.7928759894459103\n",
      "TEST Balanced Error Rate for C = 0.001: 0.3084695731153497\n",
      "VALIDATION Accuracy Score for C = 0.001: 0.787598944591029\n",
      "VALIDATION Balanced Error Rate for C = 0.001: 0.3678571428571429\n",
      "\n",
      "TRAIN Accuracy Score for C = 0.01: 0.8066006600660066\n",
      "TRAIN Balanced Error Rate for C = 0.01: 0.19658703071672345\n",
      "TEST Accuracy Score for C = 0.01: 0.783641160949868\n",
      "TEST Balanced Error Rate for C = 0.01: 0.31323796548592187\n",
      "VALIDATION Accuracy Score for C = 0.01: 0.7928759894459103\n",
      "VALIDATION Balanced Error Rate for C = 0.01: 0.3822896281800392\n",
      "\n",
      "TRAIN Accuracy Score for C = 0.1: 0.8033003300330033\n",
      "TRAIN Balanced Error Rate for C = 0.1: 0.1596587030716723\n",
      "TEST Accuracy Score for C = 0.1: 0.7770448548812665\n",
      "TEST Balanced Error Rate for C = 0.1: 0.31664396003633066\n",
      "VALIDATION Accuracy Score for C = 0.1: 0.7968337730870713\n",
      "VALIDATION Balanced Error Rate for C = 0.1: 0.2772015655577299\n",
      "\n",
      "TRAIN Accuracy Score for C = 1: 0.7973597359735973\n",
      "TRAIN Balanced Error Rate for C = 1: 0.16273037542662117\n",
      "TEST Accuracy Score for C = 1: 0.7770448548812665\n",
      "TEST Balanced Error Rate for C = 1: 0.31664396003633066\n",
      "VALIDATION Accuracy Score for C = 1: 0.7823218997361477\n",
      "VALIDATION Balanced Error Rate for C = 1: 0.31908023483365944\n",
      "\n",
      "TRAIN Accuracy Score for C = 10: 0.7993399339933993\n",
      "TRAIN Balanced Error Rate for C = 10: 0.16170648464163828\n",
      "TEST Accuracy Score for C = 10: 0.7757255936675461\n",
      "TEST Balanced Error Rate for C = 10: 0.29717302452316074\n",
      "VALIDATION Accuracy Score for C = 10: 0.7955145118733509\n",
      "VALIDATION Balanced Error Rate for C = 10: 0.27788649706457924\n",
      "\n",
      "TRAIN Accuracy Score for C = 100: 0.7986798679867987\n",
      "TRAIN Balanced Error Rate for C = 100: 0.2586348122866894\n",
      "TEST Accuracy Score for C = 100: 0.7849604221635884\n",
      "TEST Balanced Error Rate for C = 100: 0.2924046321525886\n",
      "VALIDATION Accuracy Score for C = 100: 0.7889182058047494\n",
      "VALIDATION Balanced Error Rate for C = 100: 0.3843444227005871\n",
      "\n",
      "TRAIN Accuracy Score for C = 1000: 0.7966996699669967\n",
      "TRAIN Balanced Error Rate for C = 1000: 0.1630716723549488\n",
      "TEST Accuracy Score for C = 1000: 0.7757255936675461\n",
      "TEST Balanced Error Rate for C = 1000: 0.31732515894641233\n",
      "VALIDATION Accuracy Score for C = 1000: 0.7783641160949868\n",
      "VALIDATION Balanced Error Rate for C = 1000: 0.32113502935420746\n",
      "\n",
      "TRAIN Accuracy Score for C = 10000: 0.7966996699669967\n",
      "TRAIN Balanced Error Rate for C = 10000: 0.23068259385665524\n",
      "TEST Accuracy Score for C = 10000: 0.783641160949868\n",
      "TEST Balanced Error Rate for C = 10000: 0.2930858310626703\n",
      "VALIDATION Accuracy Score for C = 10000: 0.7823218997361477\n",
      "VALIDATION Balanced Error Rate for C = 10000: 0.3877690802348337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predictions_lst = []\n",
    "vali_predictions_lst = []\n",
    "test_predictions_lst = []\n",
    "bestBER = 1\n",
    "bestModel = None\n",
    "train_ber = []\n",
    "test_ber = []\n",
    "vali_ber = []\n",
    "\n",
    "for num in [10**-4, 10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3, 10**4]:\n",
    "    model = linear_model.LogisticRegression(C=num, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    train_predictions_lst.append(model.predict(X_train))\n",
    "    vali_predictions_lst.append(model.predict(X_vali))\n",
    "    test_predictions_lst.append(model.predict(X_test))\n",
    "    \n",
    "    train_ber.append(1 - metrics.balanced_accuracy_score(y_train, model.predict(X_train)))\n",
    "    test_ber.append(1 - metrics.balanced_accuracy_score(y_test, model.predict(X_test)))\n",
    "    vali_ber.append(1 - metrics.balanced_accuracy_score(y_vali, model.predict(X_vali)))\n",
    "    \n",
    "    print('TRAIN Accuracy Score for C = ' + str(num) +':', \n",
    "          metrics.accuracy_score(y_train, model.predict(X_train)))\n",
    "    print('TRAIN Balanced Error Rate for C = ' + str(num) +':', \n",
    "          1 - metrics.balanced_accuracy_score(y_train, model.predict(X_train)))\n",
    "    \n",
    "    print('TEST Accuracy Score for C = ' + str(num) +':', \n",
    "          metrics.accuracy_score(y_test, model.predict(X_test)))\n",
    "    print('TEST Balanced Error Rate for C = ' + str(num) +':', \n",
    "          1 - metrics.balanced_accuracy_score(y_test, model.predict(X_test)))\n",
    "    \n",
    "    print('VALIDATION Accuracy Score for C = ' + str(num) +':', \n",
    "          metrics.accuracy_score(y_vali, model.predict(X_vali)))\n",
    "    print('VALIDATION Balanced Error Rate for C = ' + str(num) +':', \n",
    "          1 - metrics.balanced_accuracy_score(y_vali, model.predict(X_vali)))\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    if not bestModel or (1-metrics.balanced_accuracy_score(y_vali, model.predict(X_vali))) < bestBER:\n",
    "        bestBER = 1 - metrics.balanced_accuracy_score(y_vali, model.predict(X_vali))\n",
    "        bestModel = model\n",
    "        bestC = num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For conviniences, I created a datafrmae to show the results, where the rows are train BER, test BER, and validation BER; and columns are value of parameter C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>10000.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train BER</th>\n",
       "      <td>0.251263</td>\n",
       "      <td>0.175904</td>\n",
       "      <td>0.196587</td>\n",
       "      <td>0.159659</td>\n",
       "      <td>0.162730</td>\n",
       "      <td>0.161706</td>\n",
       "      <td>0.258635</td>\n",
       "      <td>0.163072</td>\n",
       "      <td>0.230683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test BER</th>\n",
       "      <td>0.309435</td>\n",
       "      <td>0.308470</td>\n",
       "      <td>0.313238</td>\n",
       "      <td>0.316644</td>\n",
       "      <td>0.316644</td>\n",
       "      <td>0.297173</td>\n",
       "      <td>0.292405</td>\n",
       "      <td>0.317325</td>\n",
       "      <td>0.293086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation BER</th>\n",
       "      <td>0.398728</td>\n",
       "      <td>0.367857</td>\n",
       "      <td>0.382290</td>\n",
       "      <td>0.277202</td>\n",
       "      <td>0.319080</td>\n",
       "      <td>0.277886</td>\n",
       "      <td>0.384344</td>\n",
       "      <td>0.321135</td>\n",
       "      <td>0.387769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0.0001      0.0010      0.0100      0.1000      1.0000      \\\n",
       "Train BER         0.251263    0.175904    0.196587    0.159659    0.162730   \n",
       "Test BER          0.309435    0.308470    0.313238    0.316644    0.316644   \n",
       "Validation BER    0.398728    0.367857    0.382290    0.277202    0.319080   \n",
       "\n",
       "                10.0000     100.0000    1000.0000   10000.0000  \n",
       "Train BER         0.161706    0.258635    0.163072    0.230683  \n",
       "Test BER          0.297173    0.292405    0.317325    0.293086  \n",
       "Validation BER    0.277886    0.384344    0.321135    0.387769  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "dic['Train BER'] = train_ber\n",
    "dic['Test BER'] = test_ber\n",
    "dic['Validation BER'] = vali_ber\n",
    "\n",
    "pd.DataFrame.from_dict(dic, orient='index', \n",
    "                       columns=[10**-4, 10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3, 10**4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best BER: 0.2772015655577299\n",
      "Best C: 0.1\n",
      "Best Model: LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print('Best BER:',bestBER)\n",
    "print('Best C:', bestC)\n",
    "print('Best Model:', bestModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Analysis*: Here I choose C = 0.1 as the best parameter for my best model. The reason is that when C = 0.1, the balanced error rate (BER) for validation set is the smallest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Question: Compute the Fβ scores for β = 1, β = 0.1, and β = 10 for the above classifier, using C = 1 (on the test set) (1 mark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer for Question 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Fβ scores for Beta = 1: 0.14213197969543148\n",
      "TEST Fβ scores for Beta = 0.1: 0.08162087277764951\n",
      "TEST Fβ scores for Beta = 10: 0.5495530509133307\n"
     ]
    }
   ],
   "source": [
    "for num in [1, 0.1, 10]:\n",
    "    print('TEST Fβ scores for Beta = ' + str(num) +':', \n",
    "          metrics.fbeta_score(y_test, test_predictions_3, beta = num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Question: Following the stub code, compute the PCA basis on the training set. Report the first PCA component\n",
    "(i.e., pca.components [0]) (1 mark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer for Question 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first PCA component:  [-5.66194086e-19 -2.93791278e-08  3.09022418e-07  1.18939159e-06\n",
      "  4.70743252e-06  2.44710258e-03 -1.01298099e-06  1.76546361e-06\n",
      "  5.01973388e-06 -8.98610008e-07 -9.81724115e-08  2.63187931e-07\n",
      "  1.29754258e-06  2.82880656e-07  1.76546361e-06  1.46676095e-03\n",
      "  1.09125843e-06  5.44237993e-06  1.76546361e-06  3.27935544e-07\n",
      "  6.55831910e-05  3.34752532e-08  2.35355899e-07  2.68856867e-07\n",
      "  3.88441701e-07  7.39994780e-07  9.56972844e-07 -7.78591508e-05\n",
      "  2.06501549e-06  4.21607925e-06 -1.34408394e-06  2.97861089e-07\n",
      " -6.71486060e-04  5.55451651e-06 -2.11686320e-06  2.07342347e-07\n",
      " -6.08831917e-07  6.09166474e-03 -5.53122726e-07  1.93394593e-07\n",
      "  1.45849666e-06  4.03088086e-06  2.18182907e-07  1.04657649e-04\n",
      "  3.90736605e-05 -5.51670404e-06  2.98766825e-06 -3.55291648e-04\n",
      "  2.82683039e-07  2.61717909e-07  3.89105425e-06 -8.50048254e-07\n",
      " -1.81735711e-06  3.84611281e-06  2.15330571e-06  9.99977007e-01\n",
      "  1.49609184e-07 -6.09288822e-08 -2.46028433e-07  7.08987975e-07\n",
      " -1.58988551e-04 -1.44319070e-05 -3.33176432e-04  6.63738481e-06\n",
      " -1.28207403e-05]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "print('The first PCA component: ', pca.components_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "Question: Compute the validation and test BER of a model that uses just the first N components (i.e., dimensions) for N = 5, 10, . . . , 25, 30. Again use class weight=’balanced’ and C = 1.0 (2 marks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer for Question 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Balanced Error Rate for first 5 Component: 0.40264532243415074\n",
      "VALIDATION Balanced Error Rate for first 5 Component: 0.3234344422700587\n",
      "\n",
      "TEST Balanced Error Rate for first 10 Component: 0.36960717529518616\n",
      "VALIDATION Balanced Error Rate for first 10 Component: 0.4076810176125245\n",
      "\n",
      "TEST Balanced Error Rate for first 15 Component: 0.32725930971843775\n",
      "VALIDATION Balanced Error Rate for first 15 Component: 0.4056262230919765\n",
      "\n",
      "TEST Balanced Error Rate for first 20 Component: 0.2704927338782924\n",
      "VALIDATION Balanced Error Rate for first 20 Component: 0.36232876712328765\n",
      "\n",
      "TEST Balanced Error Rate for first 25 Component: 0.301941416893733\n",
      "VALIDATION Balanced Error Rate for first 25 Component: 0.37676125244618397\n",
      "\n",
      "TEST Balanced Error Rate for first 30 Component: 0.2958106267029973\n",
      "VALIDATION Balanced Error Rate for first 30 Component: 0.3877690802348337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_ber_8 = []\n",
    "vali_ber_8 = []\n",
    "\n",
    "for num in np.arange(5, 31, 5):\n",
    "    Xpca_train = numpy.matmul(X_train, pca.components_[:num].T) \n",
    "    Xpca_valid = numpy.matmul(X_vali, pca.components_[:num].T) \n",
    "    Xpca_test = numpy.matmul(X_test, pca.components_[:num].T)\n",
    "    \n",
    "    model = linear_model.LogisticRegression(C=1.0, class_weight='balanced')\n",
    "    model.fit(Xpca_train, y_train)\n",
    "    \n",
    "    test_ber_8.append(1 - metrics.balanced_accuracy_score(y_test, model.predict(Xpca_test)))\n",
    "    vali_ber_8.append(1 - metrics.balanced_accuracy_score(y_vali, model.predict(Xpca_valid)))\n",
    "    \n",
    "    print('TEST Balanced Error Rate for first ' + str(num) +' Component:', \n",
    "          1 - metrics.balanced_accuracy_score(y_test, model.predict(Xpca_test)))\n",
    "\n",
    "    print('VALIDATION Balanced Error Rate for first ' + str(num) +' Component:', \n",
    "          1 - metrics.balanced_accuracy_score(y_vali, model.predict(Xpca_valid)))\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For conviniences, I created a datafrmae to show the results, where the rows are test BER and validation BER, and columns are number of n first components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test BER</th>\n",
       "      <td>0.402645</td>\n",
       "      <td>0.369607</td>\n",
       "      <td>0.327259</td>\n",
       "      <td>0.270493</td>\n",
       "      <td>0.301941</td>\n",
       "      <td>0.295811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation BER</th>\n",
       "      <td>0.323434</td>\n",
       "      <td>0.407681</td>\n",
       "      <td>0.405626</td>\n",
       "      <td>0.362329</td>\n",
       "      <td>0.376761</td>\n",
       "      <td>0.387769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      5         10        15        20        25        30\n",
       "Test BER        0.402645  0.369607  0.327259  0.270493  0.301941  0.295811\n",
       "Validation BER  0.323434  0.407681  0.405626  0.362329  0.376761  0.387769"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_8 = {}\n",
    "dic_8['Test BER'] = test_ber_8\n",
    "dic_8['Validation BER'] = vali_ber_8\n",
    "\n",
    "pd.DataFrame.from_dict(dic_8, orient='index', \n",
    "                       columns=[5,10,15,20,25,30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
